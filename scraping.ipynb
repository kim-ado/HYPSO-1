{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mblur\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kim\\Documents\\master\\HYPSO-1\\blur.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import blur\n",
    "import hico_batch_scraper as hs\n",
    "from http.cookiejar import CookieJar\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_name = \"hico_data\"\n",
    "\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = hs.MyHTMLParser() \n",
    "\n",
    "#===============================================================================\n",
    "# The following code block is used for HTTPS authentication\n",
    "#===============================================================================\n",
    "\n",
    "# The user credentials that will be used to authenticate access to the data\n",
    "username = \"kimado\"\n",
    "password = \"&82m%wPhE8-9.C+\"\n",
    "\n",
    "# The FULL url of the directory which contains the files you would like to bulk download\n",
    "url = \"https://oceandata.sci.gsfc.nasa.gov/directdataaccess/Level-1B/HICO/2014\" # Example URL\n",
    "\n",
    "# Create a password manager to deal with the 401 reponse that is returned from\n",
    "# Earthdata Login\n",
    " \n",
    "password_manager = urllib.request.HTTPPasswordMgrWithDefaultRealm()\n",
    "password_manager.add_password(None, \"https://urs.earthdata.nasa.gov\", username, password)\n",
    " \n",
    "# Create a cookie jar for storing cookies. This is used to store and return\n",
    "# the session cookie given to use by the data server (otherwise it will just\n",
    "# keep sending us back to Earthdata Login to authenticate).  Ideally, we\n",
    "# should use a file based cookie jar to preserve cookies between runs. This\n",
    "# will make it much more efficient.\n",
    " \n",
    "cookie_jar = CookieJar()\n",
    "\n",
    "# Install all the handlers.\n",
    "opener = urllib.request.build_opener(\n",
    "    urllib.request.HTTPBasicAuthHandler(password_manager),\n",
    "    #urllib.request.HTTPHandler(debuglevel=1),    # Uncomment these two lines to see\n",
    "    #urllib.request.HTTPSHandler(debuglevel=1),   # details of the requests/responses\n",
    "    urllib.request.HTTPCookieProcessor(cookie_jar))\n",
    "urllib.request.install_opener(opener)\n",
    " \n",
    "# Create and submit the requests. There are a wide range of exceptions that\n",
    "# can be thrown here, including HTTPError and URLError. These should be\n",
    "# caught and handled.\n",
    "\n",
    "#===============================================================================\n",
    "# Open a requeset to grab filenames within a directory. Print optional\n",
    "#===============================================================================\n",
    "\n",
    "# Get the subdirectories\n",
    "DirRequest = urllib.request.Request(url)\n",
    "DirResponse = urllib.request.urlopen(DirRequest)\n",
    "DirBody = DirResponse.read()\n",
    "parser.feed(str(DirBody))\n",
    "subdirs = parser.dataList\n",
    "\n",
    "# Get the number of subdirectories to download from\n",
    "x = 1 # Number of subdirectories to download from\n",
    "\n",
    "# Download the files from the top 'x' subdirectories\n",
    "for subdir in subdirs[:x]:\n",
    "    # Construct the URL of the subdirectory\n",
    "    subdir_url = url + subdir\n",
    "\n",
    "    # Get the files in the subdirectory\n",
    "    DirRequest = urllib.request.Request(subdir_url)\n",
    "    DirResponse = urllib.request.urlopen(DirRequest)\n",
    "    DirBody = DirResponse.read()\n",
    "    parser.feed(str(DirBody))\n",
    "    files = parser.dataList\n",
    "\n",
    "    #===============================================================================\n",
    "    # Call the function to download all files in url\n",
    "    #===============================================================================\n",
    "\n",
    "    # Download each file\n",
    "    hs.BatchJob(files, cookie_jar, subdir_url, folder_name)\n",
    "\n",
    "    # Reset the dataList for the next subdirectory\n",
    "    parser.dataList = []\n",
    "\n",
    "# Display the contents of the python list declared in the HTMLParser class\n",
    "# print Files #Uncomment to print a list of the files\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
